# Research Query: Latest updates on the progress of Google's TPU v6, Amazon's Trainium 2, and Microsoft's Maia 2 custom AI chips.
**Generated:** Wednesday, August 27, 2025 at 12:11:04 PM
**Model:** gemini-2.5-flash

## Search Queries Used
- Google TPU v6 progress updates challenges OR OR OR OR OR OR after:2025-05-27
- Amazon Trainium 2 development adoption challenges OR OR OR OR OR OR after:2025-05-27
- Microsoft Maia 2 deployment progress challenges OR OR OR OR OR OR after:2025-05-27
- Hyperscaler custom AI chip competition NVIDIA impact OR OR OR OR OR OR after:2025-05-27

## Sources Referenced
- [aicerts.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE1iWq_Z6fhWndLHZ8gBIUvo01g_PFz7VUno0P9sIWi32yyCz0CKX1o0oyGhGj0FjvY733mnjVqQoQR0piHjmkcGHREnQgH5Lie1yxq1lAyZ_TODl4bzJ7tZ4a0rqdEfnDn52GnrCYw6BidYrwLrlKLrn1gUgYST8r5t0sV6CJx5avOOOwoX8ihgbKs9860wERC2TU=)
- [forbes.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEIuwoCkDL44bMRUEir-iQLoxvwbnTkwJqTAi6HzPPCem-E95tM571WTrIkRlV9TfLsQMNki6Px5yVD3gyF0vN_R46e7p2QWJ-g1sYMeZiv6xUdeGTEcZpCx4C6Sfz7mUyrA82UkzOcf_3dz6GcqBcF23FuL0GVFotoxNLu5OZMi1AYbLq2hrcy6iyYn5Pij06TW4G8nCzAYv_1TG-MnxlBIWrlNVVxKn8=)
- [seekingalpha.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHh6dTGb97iXeaeki41Do6LRaHjOFajliWT97WUnlRot22sboHY9_IqwgYn4TbabBe8rAUgyrluNeyXXTRFujM2dsI3HP8VfUgtUVX5M5Q9R6rRWfqsTk2JTWOMTGTOok7tJh2JDVg_TDKMiRGXfPtccbxVr-cummkL418cCFZ1DoCnCw-5rsAMfGOT0wK-Gcw=)
- [ts2.tech](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGdjVgjvBs0Ly_JRtz5pjOCs915Of5rtV1HEj3AtRwznm3f1-jGvE1y6yr-x4djGYS-bRuBvpe79wpZJ-SDgsegfDK7I9ZP--BfGtU1VM0sHaySEy539rh5KP9pB2DBuMqfn1YTD3HtqM8XGfN47mm8Cttz1HDG-Hi3ubequD_jGQXFUJ0oon86bddteu69GzZjSkNgFVA18CV_QDjrq7YNdqCzyrU2hvsJxks=)
- [substack.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE0BAfROtX21DVSFjdIm1imkFx3B5J9NH-4jPUw6a0L5iRSVw2j1lQDBqIecdZze5koZ5ii94r5AzFPx-jHd6yq3jhqlJksJT3nBvH7OgONBDkBDqfeau7qtev4TrVCsuZY8zuRU7f7A8TzlgfD9s-vYcX1n84cKwn7ILlBgIWqemXGFWk=)
- [ainvest.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHgSyzJlRKkl-K7fra1eDMSakjSX2YdsJqAFDcAB28KQalPZ9_TFWMBwzCq7jOBn3YZWMyFqv2jEmyAnhdeqYZ46EAP5FMSVFOJOUisrzBnaQnsAdNKjUUwUN25-kIpsL8Mt_zcqdiYMstDvILYrbM-fL3WyxnRTZUv1KLlfSqft3JtzdiPqJXdQAjFJm4z)
- [tomshardware.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHIu35nUH_NyfA6mZj6nuF3EEtLEABN27_yNPw0F0nAkhihemL6ORlmyQ-qksPNUupW-Ty6ntdvjarigAEEFt2Vjq4Zg9Tse22UM0Axx2thL-SWYH7oznftZ9_xcY49CXaJByJkzDXETlUfWkYMMElHKxQlBu5BOapOO7AdV5gLbDkHcXZiC2tWRqPOptAfMPBVNcgbTivgLiPkreHTIROfK95IpTdI9tAcy2omNsoAnYeQunETgaMxSy_hAaQg28pe3X9XosvKyP5uxjxFkLyhgM3Q1zt3_BIZszcmwU7kUbeWdlNqmi8TTB8W87HxWIslDgTGswDvg_rz81xPTay5Ww-1L34AfyrF)

---

## Analysis

NVIDIA (NVDA) is reporting its Q2 FY2026 earnings today, August 27, 2025, after market close. As a pre-earnings research analyst, the focus is on identifying material, non-consensus information regarding the progress of custom AI chips from Google, Amazon, and Microsoft, which could influence NVIDIA's performance or forward-looking guidance. Recent developments suggest a mixed landscape of both intensifying competition and unexpected challenges for hyperscalers' in-house silicon efforts.

While hyperscalers continue to invest heavily in custom AI chips to reduce reliance on NVIDIA and optimize for their specific workloads, several recent reports indicate that the path to widespread adoption and competitive parity is not without significant hurdles. These challenges, particularly in software ecosystems and production timelines, could indirectly benefit NVIDIA by extending its market dominance in the short to medium term.

Here are the key findings:

---

**Structured Findings:**

*   **Snippet:** "Microsoft's Braga chip—part of its Maia AI chip family—was expected to go into large-scale production by late 2025. However, internal sources now confirm that unforeseen design changes, engineering challenges, and personnel turnover have delayed the rollout by at least six months. The AI chip delay not only pushes timelines but could also result in performance limitations when compared to Nvidia's Blackwell chip, currently regarded as the industry leader in AI compute."
    *   **Date:** 2025-06-09
    *   **Source:** AI CERTs News, [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE1iWq_Z6fhWndLHZ8gBIUvo01g_PFz7VUno0P9sIWi32yyCz0CKX1o0oyGhGj0FjvY733mnjVqQoQR0piHjmkcGHREnQgH5Lie1yxq1lAyZ_TODl4bzJ7tZ4a0rqdEfnDn52GnrCYw6BidYrwLrlKLrn1gUgYST8r5t0sV6CJx5avOOOwoX8ihgbKs9860wERC2TU=](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE1iWq_Z6fhWndLHZ8gBIUvo01g_PFz7VUno0P9sIWi32yyCz0CKX1o0oyGhGj0FjvY733mnjVqQoQR0piHjmkcGHREnQgH5Lie1yxq1lAyZ_TODl4bzJ7tZ4a0rqdEfnDn52GnrCYw6BidYrwLrlKLrn1gUgYST8r5t0sV6CJx5avOOOwoX8ihgbKs9860wERC2TU=)
    *   **Impact:** High. This is a significant setback for Microsoft's in-house AI chip ambitions, directly impacting its ability to reduce reliance on NVIDIA. The delay of "Braga" to 2026 and its anticipated underperformance against NVIDIA's Blackwell means Microsoft will likely continue to procure NVIDIA GPUs for critical AI workloads for a longer period than initially planned.
    *   **Consensus Check:** Overlooked. While some reports mention delays, the specific reasons (design changes, staffing, OpenAI's requests) and the direct comparison to Blackwell's superior performance, suggesting a continued reliance on NVIDIA, might not be fully priced in.

*   **Snippet:** "AWS developers found Trainium software harder to work with than CUDA, and they reportedly pushed back to management against Trainium's limitations. Management essentially said shut up and get to work. So, Trainium adoption lagged. Amazon realized it needed to invest even more to create the developers ecosystem, and it launched the Build on Trainium initiative — a $110 million investment in university research."
    *   **Date:** 2025-08-11
    *   **Source:** Forbes, [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEIuwoCkDL44bMRUEir-iQLoxvwbnTkwJqTAi6HzPPCem-E95tM571WTrIkRlV9TfLsQMNki6Px5yVD3gyF0vN_R46e7p2QWJ-g1sYMeZiv6xUdeGTEcZpCx4C6Sfz7mUyrA82UkzOcf_3dz6GcqBcF23FuL0GVFotoxNLu5OZMi1AYbLq2hrcy6iyYn5Pij06TW4G8nCzAYv_1TG-MnxlBIWrlNVVxKn8=](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEIuwoCkDL44bMRUEir-iQLoxvwbnTkwJqTAi6HzPPCem-E95tM571WTrIkRlV9TfLsQMNki6Px5yVD3gyF0vN_R46e7p2QWJ-g1sYMeZiv6xUdeGTEcZpCx4C6Sfz7mUyrA82UkzOcf_3dz6GcqBcF23FuL0GVFotoxNLu5OZMi1AYbLq2hrcy6iyYn5Pij06TW4G8nCzAYv_1TG-MnxlBIWrlNVVxKn8=)
    *   **Impact:** High. Despite Amazon's significant investment in Trainium 2 and its impressive hardware specs, the reported difficulties with its software ecosystem and internal/partner (Anthropic) pushback are critical. This suggests a slower-than-expected internal adoption and potential external customer reluctance, which would mean continued reliance on NVIDIA GPUs for many AWS AI workloads.
    *   **Consensus Check:** Overlooked. While the existence of Trainium 2 is known, the specific challenges with its software stack and the internal resistance from developers and key partners like Anthropic are likely not widely understood or factored into market expectations.

*   **Snippet:** "In fact, Google's TPU v6 is rumored to undercut on cost for internal workloads. OpenAI's recent move to use Google's TPUs is another worrying sign for Nvidia's chip dominance."
    *   **Date:** 2025-07-24
    *   **Source:** Seeking Alpha, [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHh6dTGb97iXeaeki41Do6LRaHjOFajliWT97WUnlRot22sboHY9_IqwgYn4TbabBe8rAUgyrluNeyXXTRFujM2dsI3HP8VfUgtUVX5M5Q9R6rRWfqsTk2JTWOMTGTOok7tJh2JDVg_TDKMiRGXfPtccbxVr-cummkL418cCFZ1DoCnCw-5rsAMfGOT0wK-Gcw=](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHh6dTGb97iXeaeki41Do6LRaHjOFajliWT97WUnlRot22sboHY9_IqwgYn4TbabBe8rAUgyrluNeyXXTRFujM2dsI3HP8VfUgtUVX5M5Q9R6rRWfqsTk2JTWOMTGTOok7tJh2JDVg_TDKMiRGXfPtccbxVr-cummkL418cCFZ1DoCnCw-5rsAMfGOT0wK-Gcw=)
    *   **Impact:** High. OpenAI's reported move to use Google's TPUs is a significant competitive threat to NVIDIA. OpenAI is a leading AI innovator and a major consumer of AI compute. If they are diversifying their hardware usage to include TPUs, it signals a viable alternative to NVIDIA's GPUs, potentially impacting NVIDIA's long-term market share and pricing power, especially for large-scale training workloads.
    *   **Consensus Check:** Medium. While the general competition from hyperscaler custom chips is known, a specific high-profile customer like OpenAI reportedly shifting some workloads to TPUs could be a non-consensus data point with material implications.

*   **Snippet:** "Google's TPU v6e, codenamed Trillium, delivers 918 TFLOPS BF16 per chip... The v6e 'Trillium' appears to close much of the gap with NVIDIA's Hopper/Blackwell in raw compute: e.g., 918 TF BF16 is in the ballpark of an NVIDIA H100's ~1,000 TF FP16, although a single Blackwell B200 at ~4,500 TF16 is much higher. However, Google can deploy 256 of these chips (or even larger multi-pod clusters with optical interconnects), achieving performance that rivals supercomputers."
    *   **Date:** 2025-08-05
    *   **Source:** TS2 Space, [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGdjVgjvBs0Ly_JRtz5pjOCs915Of5rtV1HEj3AtRwznm3f1-jGvE1y6yr-x4djGYS-bRuBvpe79wpZJ-SDgsegfDK7I9ZP--BfGtU1VM0sHaySEy539rh5KP9pB2DBuMqfn1YTD3HtqM8XGfN47mm8Cttz1HDG-Hi3ubequD_jGQXFUJ0oon86bddteu69GzZjSkNgFVA18CV_QDjrq7YNdqCzyrU2hvsJxks=](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGdjVgjvBs0Ly_JRtz5pjOCs915Of5rtV1HEj3AtRwznm3f1-jGvE1y6yr-x4djGYS-bNFfGtU1VM0sHaySEy539rh5KP9pB2DBuMqfn1YTD3HtqM8XGfN47mm8Cttz1HDG-Hi3ubequD_jGQXFUJ0oon86bddteu69GzZjSkNgFVA18CV_QDjrq7YNdqCzyrU2hvsJxks=)
    *   **Impact:** Medium. While a single Blackwell B200 still significantly outperforms a single TPU v6e, the ability of Google to deploy massive, highly interconnected clusters of TPUs means they can achieve supercomputer-level performance for their internal workloads. This reinforces the idea that Google is increasingly self-sufficient for its most demanding AI tasks.
    *   **Consensus Check:** Medium. The raw specs of TPU v6e are likely known, but the emphasis on its cluster-scale performance and its ability to rival NVIDIA's top-tier GPUs in aggregate for specific workloads might be underappreciated.

*   **Snippet:** "For years, Google has primarily partnered with Broadcom for the development of its TPU series, particularly for the fifth and sixth generations (TPU v5 / v6 Trillium), with Broadcom providing extensive custom ASIC design support. However, as the cost of large AI models continues to rise and cloud infrastructure faces mounting pressure, Google is now expanding its supplier base in search of greater cost-efficiency and design flexibility. The collaboration with MediaTek focuses on the..."
    *   **Date:** 2025-07-14
    *   **Source:** semivision, [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE0BAfROtX21DVSFjdIm1imkFx3B5J9NH-4jPUw6a0L5iRSVw2j1lQDBqIecdZze5koZ5ii94r5AzFPx-jHd6yq3jhqlJksJT3nBvH7OgONBDkBDqfeau7qtev4TrVCsuZY8zuRU7f7A8TzlgfD9s-vYcX1n84cKwn7ILlBgIWqemXGFWk=](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE0BAfROtX21DVSFjdIm1imkFx3B5J9NH-4jPUw6a0L5iRSVw2j1lQDBqIecdZze5koZ5ii94r5AzFPx-jHd6yq3jhqlJksJT3nBvH7OgONBDkBDqfeau7qtev4TrVCsuZY8zuRU7f7A8TzlgfD9s-vYcX1n84cKwn7ILlBgIWqemXGFWk=)
    *   **Impact:** Medium. Google's diversification of its TPU supplier base to include MediaTek, moving beyond Broadcom, suggests a strategic effort to accelerate development, improve cost-efficiency, and enhance design flexibility for future TPU generations. This could lead to faster iteration and deployment of more competitive custom silicon, increasing long-term pressure on NVIDIA.
    *   **Consensus Check:** Overlooked. The specific details of Google's supply chain partners for TPUs and the strategic shift to include MediaTek are likely not widely known outside of niche industry circles.

*   **Snippet:** "AWS's slower AI adoption has tangible financial consequences. Its operating margin contracted to 32.9% in Q2 2025, the lowest since late 2023, as it invests heavily in AI infrastructure like Trainium chips and Bedrock. While Trainium offers a 30–40% price-performance edge over NVIDIA-based solutions, this cost advantage has not translated into higher margins."
    *   **Date:** 2025-08-01
    *   **Source:** AInvest, [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHgSyzJlRKkl-K7fra1eDMSakjSX2YdsJqAFDcAB28KQalPZ9_TFWMBwzCq7jOBn3YZWMyFqv2jEmyAnhdeqYZ46EAP5FMSVFOJOUisrzBnaQnsAdNKjUUwUN25-kIpsL8Mt_zcqdiYMstDvILYrbM-fL3WyxnRTZUv1KLlfSqft3JtzdiPqJXdQAjFJm4z](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHgSyzJlRKkl-K7fra1eDMSakjSX2YdsJqAFDcAB28KQalPZ9_TFWMBwzCq7jOBn3YZWMyFqv2jEmyAnhdeqYZ46EAP5FMSVFOJOUisrzBnaQnsAdNKjUUwUN25-kIpsL8Mt_zcqdiYMstDvILYrbM-fL3WyxnRTZUv1KLlfSqft3JtzdiPqJXdQAjFJm4z)
    *   **Impact:** Medium. The contraction of AWS's operating margin in Q2 2025, despite heavy investments in Trainium and its claimed price-performance advantage, suggests that Amazon's custom silicon strategy is not yet yielding the expected financial benefits or competitive edge in AI adoption. This could imply continued, or even increased, reliance on NVIDIA for certain high-margin AI workloads where NVIDIA's ecosystem is more mature and readily adopted.
    *   **Consensus Check:** Overlooked. While AWS's overall performance is tracked, the specific link between Trainium investments, lagging AI adoption, and margin contraction, especially in Q2 2025, might be a non-consensus detail.

---

**Human-Readable Analysis:**

NVIDIA's upcoming earnings report will be closely watched for signs of how the burgeoning custom AI chip market is impacting its dominant position. Recent intelligence suggests a nuanced picture.

On one hand, **Microsoft's ambitions for its Maia 2 (Braga) chip have hit a significant snag**, with production delayed by at least six months into 2026 due to design challenges, engineering hurdles, and even personnel turnover. Crucially, reports indicate that the delayed Braga chip is expected to "fall well short of the performance of Nvidia's flagship Blackwell chip." This directly implies that Microsoft will likely remain heavily dependent on NVIDIA's GPUs for its cutting-edge AI workloads for a longer duration than it had planned, potentially bolstering NVIDIA's near-to-medium term revenue from Azure.

Similarly, **Amazon's Trainium 2, despite its impressive hardware specifications and a massive 40,000-chip UltraCluster, is facing adoption challenges related to its software ecosystem.** AWS developers and even engineers at key partner Anthropic have reportedly found Trainium's software harder to work with than NVIDIA's CUDA, leading to lagged adoption and a preference for NVIDIA's mature stack. This friction suggests that Amazon's efforts to internalize AI compute may be slower to bear fruit in terms of displacing NVIDIA, and its Q2 2025 operating margin contraction, despite heavy Trainium investments, further underscores that the cost advantage isn't yet translating into a competitive edge.

Conversely, **Google's TPU v6 (Trillium) appears to be making more substantial progress.** Announced at Google I/O 2024, Trillium is closing the raw compute gap with NVIDIA's Hopper/Blackwell in BF16 performance, and Google's ability to deploy massive 256-chip pods (or larger clusters) allows it to achieve supercomputer-level performance for its internal AI models like Gemini 1.5 and Imagen 3. A particularly material, non-consensus detail is the **rumored move by OpenAI to utilize Google's TPUs for some of its workloads.** If true, this signals a significant validation of Google's custom silicon and a potential erosion of NVIDIA's dominance even among its most prominent customers. Furthermore, Google is strategically expanding its TPU supplier base to include MediaTek, moving beyond Broadcom, in pursuit of greater cost-efficiency and design flexibility, which could accelerate future TPU development.

In summary, while Microsoft and Amazon face notable headwinds in their custom AI chip initiatives, potentially extending their reliance on NVIDIA, Google's TPU v6 appears to be a more formidable and rapidly advancing competitor. The reported OpenAI adoption of TPUs, if confirmed, could be a key indicator of a shifting landscape that NVIDIA investors should closely monitor, even as the immediate challenges for other hyperscalers might provide some near-term tailwinds for NVIDIA's earnings.