# Research Query: Latest independent benchmarks of AMD's Instinct MI350 vs. NVIDIA's Blackwell B200.
**Generated:** Wednesday, August 27, 2025 at 12:06:19 PM
**Model:** gemini-2.5-flash

## Search Queries Used
- AMD Instinct MI350 vs NVIDIA Blackwell B200 independent benchmarks
- MI350 B200 performance comparison
- AMD MI350 NVIDIA B200 competitive analysis
- Blackwell B200 benchmarks vs MI350
- AMD Instinct MI350 release date performance
- NVIDIA Blackwell B200 early benchmarks
- MI350 vs B200 AI performance
- MI350 vs B200 deep learning benchmarks
- MI350 vs B200 HPC benchmarks
- MI350 vs B200 power efficiency

## Sources Referenced
- [crn.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG1cOSw3N7r-z17rBUtSfnFp-cKZ_hysEYNIsoAKJXo0R583lw1uLF4VfQY0Hyd23XycsXYQL0JtfZC_lQLld3sUTBOxy6Y-jFFORpThFww3sWO24Tqk1dBu6Pi2wwZmpr7vym-TliADMZs8yn34FHMJPG0ihn9zkhE6o8eTiiAoJsOVIIPH5SDqCBGd0WipH-bewG4IfM3K4-gPgPxLe5nXO5jYJ6oc-BiDou5R4G2Iz6rhOLRrDMvRg==)
- [guru3d.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFIbV8-r6g5DAkMX0byq39pFN9wcKxP--CJlJGQ2qZ7irziEuFSz6RR8_l3p8p6SR_Od_Kh4qTCFljzUqVo2zcBs0_LdWa6DvmJRftffrG8-Dqeg-7bKfJO8D1WojI75XXKkCY4VGnClFQen4QJ8AF4k5muYg2hKq-r7e48dQE=)
- [semianalysis.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHR93686Q2h119NBcIfq1NNacdCw59XXnI89F9b2PajSZiCudeg8lHiwE_A7K1KwlZHGZC_miLvOYukNl_vXuy_FtBCrqSvRNl69w8jCY83cH0wffCHMQdxum99lv_mY_Jv3FClaMWrb82rCwJM_kr8Om7Be9UcZYbgQ9LL968aiTCyDy3iPRXxHVfQLoOx2L7z0wcBcMIKytC0ZTx1LGWS88dNdjSqy1phNq4anoU=)
- [lightly.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEQ0wqHj1Ep_QGZkgsZ21D0P3RfDRwTbGw_QWdmQORswvlOitR0kSgYHnxe0_e5-MENYsDtNsFsw0EjP3SR8I-a6FMlMW-0L6ib9kroXs5qFDgC5Djz3z6llReiZKxqj6fJgRlHpdaLjTKp)
- [xda-developers.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHYdZdkogeTmAEk_fSf5x13z6uaGHzWGVLlMOwe9Q06CZscL37o7-pI-gJQmhEUQ6OvgsNutfyAR5uISnZjKwtYnmcwKpLaViDGyhsSLi0XGCP5IlnWbg3MG86Lqw_jNzruoqaVTgW9lHJhshqn1SRJMdEf)
- [techovedas.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGTafp1rec9A8fBj-u9ofFQPYTOn6LokHMNpUBDKWUykyLrhNnMx2TZPqI5F_Tc-qVPKwGNLZpgVoS27_NMtK0JK119W6nA8U1Oa8pKxJCWbm-lN3NNbOmcDIW7Egt-SmMvL4IydyVnNexo4pci9o8xwtN8tc5DLdnlp9Mk4gvgOe4GeULBHrnSiQHg)
- [tomshardware.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHmaCcrF2AGtcPy7v4qMokos2lrB3a9N1b7Nw5s4p6jE2TwtSlw22eoKWja9_HwdlVzS912Zmez0Rr8pnM_20lA_UdysQrTzSOfC5B61CqlJaNIsVd9b_qdq2CaiW2TZjPZQD6yZWM7DkDmzkOGys0-l6z9ABuBZ539oYBHbKQFZqWJmUEQQwzKPhiXWhKBPIngONrLk_8YOR-l75ahVxe-bMqvZay2nuE7v_kIYW2D_bVKpT4lM0_62w_OuRExaUUc8-_YyW3Ey1jaEH8mfct2VhSqEo_6D6ScPF_DkGbUFflVP5yu1iyvrUSj2g==)
- [diskmfr.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF3_O5L-6z8e8KRbZE-3KoTJldaY3gk_pAJzLvY5Iou7x21R12ieujUtBwisUayBtXFiGJ7qF_iTWViWGmHbXHTLSBC489queCbn-Sb1Po8wNKyGIui8Qgsk804H-hDVo8tVWPoBXh-WKldRT0qUAjCaDA9cgovMQD0nJpSXcNgS7Nh7qwc75I=)
- [nextplatform.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEwS1BguHAdSjdA28cMh2zDpZp_FbFG6r3jEysZYibyL7eFbujUqj_E97MlXA8aIvKPB5KlBedr5h9rndgrWLPUn4lLg_RYeaiwDCSi-CAoe6lDlO7vIMSSFTRpnUDFM0ANFBtDSKQIH0YRkkNh3_gPdadLL1S8flQEZok_We59w0bLxt8hJvJ7BCkYXV_YZ0c8z6uO-E8=)

---

## Analysis

As a specialized pre-earnings research analyst for NVIDIA (NVDA), I have focused on extracting material, non-consensus information regarding the competitive landscape between AMD's Instinct MI350 series and NVIDIA's Blackwell B200, with a filter for web content published within the last three months. NVIDIA reports Q2 FY2026 earnings today, August 27, 2025.

My research indicates a nuanced competitive environment. While AMD is aggressively positioning its MI350 series with strong performance and cost claims, particularly in memory capacity and certain inference workloads, an independent analysis suggests NVIDIA's B200 currently holds a dominant position in key benchmarks and highlights potential challenges for AMD in terms of product availability and software maturity. NVIDIA's established software ecosystem (CUDA) remains a significant competitive advantage, though AMD is making strides with its ROCm stack.

The key non-consensus information revolves around the actual, independently verified performance and availability of AMD's MI350 series, which appears to be lagging AMD's ambitious public statements. This could imply a more favorable near-term competitive landscape for NVIDIA than some might assume based solely on AMD's marketing.

Here are the key findings:

---

**Structured Findings:**

*   **Snippet:** "AMD said its forthcoming Instinct MI350 series GPUs provide greater memory capacity and better or similar AI performance compared to Nvidia's fastest Blackwell-based chips, which the company called “significantly more expensive.” ... The MI355X can also perform 10 petaflops of peak 8-bit floating point (FP8), which AMD said is on par with the GB200 but 10 percent faster than the B200; five petaflops of peak 16-bit floating point (FP16), which it said is on par with the GB200 but 10 percent faster than the B200; and 79 teraflops of 64-bit floating point (FP64), which it said is double that of the GB200 and B200. ... AMD said the MI355X “delivers the highest inference throughput” for large models, with the GPU providing roughly 20 percent better performance for the DeepSeek R1 model and approximately 30 percent better performance for a 405-billion-parameter Llama 3.1 model than the B200. Compared to the GB200, the company said the MI355X is on par when it comes to the same 405-billion-paramater Llama 3.1 model."
    *   **Date:** 2025-06-12
    *   **Source:** CRN, [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG1cOSw3N7r-z17rBUtSfnFp-cKZ_hysEYNIsoAKJXo0R583lw1uLF4VfQY0Hyd23XycsXYQL0JtfZC_lQLld3sUTBOxy6Y-jFFORpThFww3sWO24Tqk1dBu6Pi2wwZmpr7vym-TliADMZs8yn34FHMJPG0ihn9zkhE6o8eTiiAoJsOVIIPH5SDqCBGd0WipH-bewG4IfM3K4-gPgPxLe5nXO5jYJ6oc-BiDou5R4G2Iz6rhOLRrDMvRg==](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG1cOSw3N7r-z17rBUtSfnFp-cKZ_hysEYNIsoAKJXo0R583lw1uLF4VfQY0Hyd23XycsXYQL0JtfZC_lQLld3sUTBOxy6Y-jFFORpThFww3sWO24Tqk1dBu6Pi2wwZmpr7vym-TliADMZs8yn34FHMJPG0ihn9zkhE6o8eTiiAoJsOVIIPH5SDqCBGd0WipH-bewG4IfM3K4-gPgPxLe5nXO5jYJ6oc-BiDou5R4G2Iz6rhOLRrDMvRg==)
    *   **Impact:** High. These are direct and strong performance claims from AMD, suggesting the MI350 series is highly competitive or even superior to NVIDIA's Blackwell chips in specific AI inference and compute tasks, and offers double the FP64 performance. If these claims translate into widespread customer adoption, it could significantly impact NVIDIA's market share and future revenue guidance.
    *   **Consensus Check:** Widely known, as these are AMD's public claims from their "Advancing AI" event. The market's full acceptance of these claims as independently verified fact is the non-consensus aspect.

*   **Snippet:** "The MI355X and MI350X both feature 288 GB of HBM3e memory, which is higher than the 256-GB capacity of its MI325X and roughly 60 percent higher than the capacity of Nvidia's B200 GPU and GB200 Superchip, according to AMD. ... AMD's Instinct MI350 graphics accelerator has entered the AI GPU landscape at a net transaction cost of $25,000 after accounting for a standard 12 percent deduction from the reported sticker price. This strategic pricing places the MI350 solidly below Nvidia's B200, which commands over $35,000, effectively carving out roughly a 30 percent cost-performance gap in AMD's favor."
    *   **Date:** 2025-06-12 (CRN), 2025-07-30 (Guru3D)
    *   **Source:** CRN, [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG1cOSw3N7r-z17rBUtSfnFp-cKZ_hysEYNIsoAKJXo0R583lw1uLF4VfQY0Hyd23XycsXYQL0JtfZC_lQLld3sUTBOxy6Y-jFFORpThFww3sWO24Tqk1dBu6Pi2wwZmpr7vym-TliADMZs8yn34FHMJPG0ihn9zkhE6o8eTiiAoJsOVIIPH5SDqCBGd0WipH-bewG4IfM3K4-gPgPxLe5nXO5jYJ6oc-BiDou5R4G2Iz6rhOLRrDMvRg==](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG1cOSw3N7r-z17rBUtSfnFp-cKZ_hysEYNIsoAKJXo0R583lw1uLF4VfQY0Hyd23XycsXYQL0JtfZC_lQLld3sUTBOxy6Y-jFFORpThFww3sWO24Tqk1dBu6Pi2wwZmpr7vym-TliADMZs8yn34FHMJPG0ihn9zkhE6o8eTiiAoJsOVIIPH5SDqCBGd0WipH-bewG4IfM3K4-gPgPxLe5nXO5jYJ6oc-BiDou5R4G2Iz6rhOLRrDMvRg==); Guru3D, [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFIbV8-r6g5DAkMX0byq39pFN9wcKxP--CJlJGQ2qZ7irziEuFSz6RR8_l3p8p6SR_Od_Kh4qTCFljzUqVo2zcBs0_LdWa6DvmJRftffrG8-Dqeg-7bKfJO8D1WojI75XXKkCY4VGnClFQen4QJ8AF4k5muYg2hKq-r7e48dQE=](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFIbV8-r6g5DAkMX0byq39pFN9wcKxP--CJlJGQ2qZ7irziEuFSz6RR8_l3p8p6SR_Od_Kh4qTCFljzUqVo2zcBs0_LdWa6DvmJRftffrG8-Dqeg-7bKfJO8D1WojI75XXKkCY4VGnClFQen4QJ8AF4k5muYg2hKq-r7e48dQE=)
    *   **Impact:** High. The MI350 series' significantly higher memory capacity (288GB HBM3e vs. 180GB for B200) is crucial for training larger AI models. Coupled with a claimed 30% lower price point and 40% more "tokens per dollar" for inference, this presents a compelling value proposition from AMD that could pressure NVIDIA's pricing and margins in the long run.
    *   **Consensus Check:** While AMD's strategy of competitive pricing and strong memory specs is generally known, the specific magnitude of the price differential and "tokens per dollar" advantage are important details that could be overlooked by some investors.

*   **Snippet:** "The B200 with TensorRT LLM, labeled as B200-TRT, dominates the LLaMA 70B benchmark, offering lower latency and higher throughput across the board. The MI325X and MI300X are very far from competing with the B200. ... The MI355X will start shipping in late 2025, two quarters after B200 shipments commence. ... In terms of nightly accuracy, AMD had ZERO accuracy tests until SemiAnalysis pointed out accuracy issues three weeks ago. For most models, we observe worse accuracy quality on AMD when compared to using NVIDIA. 25% of the tested models are failing accuracy tests when run on AMD."
    *   **Date:** 2025-05-23
    *   **Source:** SemiAnalysis, [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHR93686Q2h119NBcIfq1NNacdCw59XXnI89F9b2PajSZiCudeg8lHiwE_A7K1KwlZHGZC_miLvOYukNl_vXuy_FtBCrqSvRNl69w8jCY83cH0wffCHMQdxum99lv_mY_Jv3FClaMWrb82rCwJM_kr8Om7Be9UcZYbgQ9LL968aiTCyDy3iPRXxHVfQLoOx2L7z0wcBcMIKytC0ZTx1LGWS88dNdjSqy1phNq4anoU=](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHR93686Q2h119NBcIfq1NNacdCw59XXnI89F9b2PajSZiCudeg8lHiwE_A7K1KwlZHGZC_miLvOYukNl_vXuy_FtBCrqSvRNl69w8jCY83cH0wffCHMQdxum99lv_mY_Jv3FClaMWrb82rCwJM_kr8Om7Be9UcZYbgQ9LL968aiTCyDy3iPRXxHVfQLoOx2L7z0wcBcMIKytC0ZTx1LGWS88dNdjSqy1phNq4anoU=)
    *   **Impact:** High. This is highly non-consensus and directly contradicts AMD's performance narrative. The assertion that B200 "dominates" and that MI355X shipments are delayed until "late 2025" (after B200 shipments commenced) suggests NVIDIA has a longer competitive lead in the immediate term. Crucially, the reported "worse accuracy quality" and "25% of tested models failing accuracy tests" on AMD's platform is a significant, often overlooked, barrier to adoption that could severely impact AMD's ability to gain market share, thereby strengthening NVIDIA's position.
    *   **Consensus Check:** Overlooked/Non-consensus. This report provides a critical counter-narrative to AMD's public claims and highlights potential weaknesses for AMD and strengths for NVIDIA that may not be fully appreciated by the broader market.

*   **Snippet:** "We got early access to NVIDIA's new Blackwell B200 GPUs and benchmarked them against cloud-based H100s (Nebius) on real-world AI tasks: computer vision pretraining (YOLOv8+DINOv2) and LLM inference (Ollama with Gemma/DeepSeek). ... The B200 is around 33% faster for AI model training than the H100 for the same workload. If we make use of the larger memory to increase the batch size we can increase the speedup to 57%. ... Software for the B200 and GB200 is still not fully fleshed out."
    *   **Date:** 2025-08-05 (Lightly.ai Blog), 2025-05-23 (SemiAnalysis)
    *   **Source:** Lightly.ai Blog, [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEQ0wqHj1Ep_QGZkgsZ21D0P3RfDRwTbGw_QWdmQORswvlOitR0kSgYHnxe0_e5-MENYsDtNsFsw0EjP3SR8I-a6FMlMW-0L6ib9kroXs5qFDgC5Djz3z6llRejZKxqj6fJgRlHpdaLjTKp](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEQ0wqHj1Ep_QGZkgsZ21D0P3RfDRwTbGw_QWdmQORswvlOitR0kSgYHnxe0_e5-MENYsDtNsFsw0EjP3SR8I-a6FMlMW-0L6ib9kroXs5qFDgC5Djz3z6llRejZKxqj6fJgRlHpdaLjTKp); SemiAnalysis, [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHR93686Q2h119NBcIfq1NNacdCw59XXnI89F9b2PajSZiCudeg8lHiwE_A7K1KwlZHGZC_miLvOYukNl_vXuy_FtBCrqSvRNl69w8jCY83cH0wffCHMQdxum99lv_mY_Jv3FClaMWrb82rCwJM_kr8Om7Be9UcZYbgQ9LL968aiTCyDy3iPRXxHVfQLoOx2L7z0wcBcMIKytC0ZTx1LGWS88dNdjSqy1phNq4anoU=](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHR93686Q2h119NBcIfq1NNacdCw59XXnI89F9b2PajSZiCudeg8lHiwE_A7K1KwlZHGZC_miLvOYukNl_vXuy_FtBCrqSvRNl69w8jCY83cH0wffCHMQdxum99lv_mY_Jv3FClaMWrb82rCwJM_kr8Om7Be9UcZYbgQ9LL968aiTCyDy3iPRXxHVfQLoOx2L7z0wcBcMIKytC0ZTx1LGWS88dNdjSqy1phNq4anoU=)
    *   **Impact:** Medium-High. While B200's generational performance uplift over H100 is generally anticipated, these real-world benchmarks provide concrete evidence of its capabilities (up to 57% faster training). The observation that "Software for the B200 and GB200 is still not fully fleshed out" is a non-consensus point that could imply further performance optimization potential for NVIDIA as its software stack matures, or it could signal temporary integration challenges.
    *   **Consensus Check:** B200's generational leap is largely known. The comment on software maturity is a more nuanced, potentially overlooked detail.

*   **Snippet:** "AMD says its new Instinct GPUs deliver somewhere between a 2.4x and nearly a 4x improvement over the MI325X, but the vast majority of that improvement doesn't come from hardware. It comes from software. Simply through optimizing ROCm — AMD's open-source software stack that's an answer to Nvidia CUDA — AMD says it's delivered a 3x performance improvement in AI training and 3.5x improvement in AI inference on the same hardware."
    *   **Date:** 2025-06-12
    *   **Source:** XDA Developers, [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHYdZdkogeTmAEk_fSf5x13z6uaGHzWGVLlMOwe9Q06CZscL37o7-pI-gJQmhEUQ6OvgsNutfyAR5uISnZjKwtYnmcwKpLaViDGyhsSLi0XGCP5IlnWbg3MG86Lqw_jNzruoqaVTgW9lHJhshqn1SRJMdEf](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHYdZdkogeTmAEk_fSf5x13z6uaGHzWGVLlMOwe9Q06CZscL37o7-pI-gJQmhEUQ6OvgsNutfyAR5uIGyhsSLi0XGCP5IlnWbg3MG86Lqw_jNzruoqaVTgW9lHJhshqn1SRJMdEf)
    *   **Impact:** Medium. This highlights AMD's significant and rapid progress in its ROCm software stack, which is critical for challenging NVIDIA's long-standing CUDA dominance. If AMD can continue to deliver substantial software-driven performance improvements, it could gradually erode NVIDIA's ecosystem advantage over the longer term.
    *   **Consensus Check:** The importance of AMD's software stack is generally known, but the magnitude of claimed software-driven performance improvements (3x-3.5x on the same hardware) is a specific detail that might be overlooked.

*   **Snippet:** "Nvidia's B200 is part of its Hopper GPU architecture and has been the industry standard for AI training tasks. It powers many of the world's most advanced AI systems, including those run by OpenAI and Google. What makes B200 dominant is Nvidia's CUDA software ecosystem, which has been refined over decades and is deeply embedded in AI development pipelines. Plus, Nvidia offers a complete stack—including networking and AI software libraries—making it the go-to for turnkey AI infrastructure."
    *   **Date:** 2025-06-17
    *   **Source:** Techovedas, [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGTafp1rec9A8fBj-u9ofFQPYTOn6LokHMNpUBDKWUykyLrhNnMx2TZPqI5F_Tc-qVPKwGNLZpgVoS27_NMtK0JK119W6nA8U1Oa8pKxJCWbm-lN3NNxwtN8tc5DLdnlp9Mk4gvgOe4GeULBHrnSiQHg](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGTafp1rec9A8fBj-u9ofFQPYTOn6LokHMNpUBDKWUykyLrhNnMx2TZPqI5F_Tc-qVPKwGNLZpgVoS27_NMtK0JK119W6nA8U1Oa8pKxJCWbm-lN3NNxwtN8tc5DLdnlp9Mk4gvgOe4GeULBHrnSiQHg)
    *   **Impact:** Medium. This reinforces NVIDIA's enduring and deeply entrenched competitive moat, which extends beyond raw hardware specifications to its comprehensive software ecosystem and full-stack solutions. This long-term advantage makes it difficult for competitors to displace NVIDIA quickly, even with competitive hardware.
    *   **Consensus Check:** Widely known, but important to reiterate as a fundamental strength for NVIDIA that underpins its market dominance.

---

**Contradictions and Gaps:**

*   **Performance Claims:** There is a significant contradiction between AMD's aggressive performance claims for the MI355X (outperforming B200 in certain inference tasks, matching GB200) and the independent SemiAnalysis report, which states the B200 "dominates" and older AMD chips are "very far from competing". This divergence highlights the need for more independent, third-party benchmarks to validate performance claims.
*   **Availability:** AMD states the MI350X/MI355X are "shipping to customers now" and will be broadly available in Q3 2025. However, SemiAnalysis reports that the MI355X will start shipping "late 2025, two quarters after B200 shipments commenced". Given NVIDIA's earnings are today (August 27, 2025, for Q2 FY2026 ending July 2025), a delay in MI355X availability would mean NVIDIA faces less direct competition from AMD's latest generation in the immediate future.
*   **Software Accuracy:** The SemiAnalysis report's finding of "worse accuracy quality on AMD" with 25% of tested models failing accuracy tests is a critical, non-consensus point. While AMD is improving its ROCm software, this accuracy issue could be a significant deterrent for customers and is not widely discussed in other reports.
*   **Independent Benchmarks:** Many of the performance comparisons cited are based on company-provided data or claims from events. Truly independent, comprehensive benchmarks directly comparing the MI350 series against the B200 across a wide range of real-world AI workloads are still emerging. The MLPerf results for B200 are primarily against NVIDIA's own H100/H200, not AMD's latest.

**Material Impact for NVIDIA's Upcoming Earnings:**

The most material non-consensus information is the SemiAnalysis report, which suggests NVIDIA's Blackwell B200 maintains a dominant performance lead in key LLM inference benchmarks and highlights potential delays and software accuracy issues for AMD's MI350 series. If AMD's latest chips are indeed delayed and have software accuracy challenges, it implies a longer runway for NVIDIA's Blackwell platform without significant direct competition from AMD's newest generation. This could lead to stronger-than-expected forward-looking guidance for NVIDIA, as the market might be factoring in a more immediate and robust competitive threat from AMD based on AMD's public statements. Conversely, the market may already be aware of these nuances, and NVIDIA's guidance will reflect its current order book and production capabilities. However, the specific details about AMD's software accuracy are particularly non-consensus and could be a significant differentiator in customer decision-making.